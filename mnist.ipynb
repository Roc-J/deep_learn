{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 往期回顾\n",
    "\n",
    "在之前的文章中，已经掌握了机器学习的基本套路，对模型，目标函数，优化算法这些概念有了一定程度的理解，而且已经会训练单个的感知器或者线性单元了。在这篇文章中，我们将把这些独立的单元按照一定的规则相互链接在一起形成神经网络，从而获得强大的学习能力。我们还将介绍这种网络的训练算法：反向传播算法。\n",
    "\n",
    "## 神经元\n",
    "神经元和感知器本质上是一样的，只不过我们说感知器的时候，它的激活函数是阶跃函数，而我们说神经元时，激活函数往往选择为sigmoid函数或者tanh函数。\n",
    "\n",
    "![](http://upload-images.jianshu.io/upload_images/2256672-49f06e2e9d3eb29f.gif)\n",
    "\n",
    "sigmoid函数是一个非线性函数，值域是(0, 1)。函数图像如下图\n",
    "\n",
    "![](http://upload-images.jianshu.io/upload_images/2256672-e7e64f57dc6b1c64.jpg)\n",
    "\n",
    "## 神经网络是啥\n",
    "\n",
    "![](http://upload-images.jianshu.io/upload_images/2256672-92111b104ce0d571.jpeg)\n",
    "\n",
    "神经网络其实就是按照一定规则连接起来的多个神经元。上图展示了一个全连接神经网络，通过观察上面的图，可以发现它的规则包括：\n",
    "* 神经元按照层来布局。 最左边的层叫做输入层，负责接收输入数据；最右边的层叫输出层，我们可以从这层获得神经网络输出数据。输入层和输出层之间的层叫做隐藏层，因为他们对于外部来说是不可见的。\n",
    "* 同一层的每个神经元和第N-1层的所有神经元相连（这是全连接），第N-1层神经元的输出就是第N层神经元的输入。\n",
    "* 每个连接都有一个权值。\n",
    "\n",
    "上面这些规则定义了全连接神经网络的结构。事实上还存在很多其他结构的神经网络，比如卷积神经网络(CNN)，循环神经网络（RNN)，他们具有不同的连接规则。\n",
    "\n",
    "## 计算神经网络的输出\n",
    "![](http://upload-images.jianshu.io/upload_images/2256672-bfbb364740f898d1.png)\n",
    "\n",
    "## 神经网络的训练\n",
    "现在，需要知道一个神经网络的每个连接上的权值是如何得到的。我们可以说神经网络是一个模型，那么这些权值就是模型的参数，也就是模型要学习的东西。然而，一个神经网络的连接方式，网络的层数，每层的节点数这些参数，则不是学习出来的，而是人为设置的参数，我们称之为超参数。\n",
    "\n",
    "### 反向传播算法(Back Propagation)\n",
    "\n",
    "## 神经网络的实现\n",
    "基本模型：\n",
    "\n",
    "![](http://upload-images.jianshu.io/upload_images/2256672-2fbae2ee722fbef9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/360)\n",
    "\n",
    "如上图，可以分解5个领域对象来实现神经网络:\n",
    "* Network神经网络对象，提供API接口。它由若干层对象组成以及连接对象组成。\n",
    "* Layer层对象，由多个节点组成\n",
    "* Node节点对象计算和记录节点自身的信息（比如输出值a，误差项delta等），以及与这个节点相关的上下游的连接。\n",
    "* connection每个连接对象都要记录该连接的权重。\n",
    "* connection仅仅作为Connection的集合对象，提供一些集合操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node节点类，负责记录和维护节点信息以及与这个节点相关的上下游连接，实现输出值和误差项的计算\n",
    "class Node(object):\n",
    "    def __init__(self, layer_index, node_index):\n",
    "        '''\n",
    "        构造节点对象\n",
    "        layer_index 节点所属的层的编号\n",
    "        node_index：节点的编号\n",
    "        '''\n",
    "        self.layer_index = layer_index\n",
    "        self.node_index = node_index\n",
    "        self.downstream = []\n",
    "        self.upstream = []\n",
    "        self.output = 0\n",
    "        self.delta = 0\n",
    "        \n",
    "    def set_output(self, output):\n",
    "        '''\n",
    "        设置节点的输出值。如果节点属于输入层会用到这个函数\n",
    "        '''\n",
    "        self.output = output\n",
    "        \n",
    "    def append_downstream_connection(self, conn):\n",
    "        '''\n",
    "        添加一个到下游节点的连接\n",
    "        '''\n",
    "        self.downstream.append(conn)\n",
    "    \n",
    "    def append_upstream_connection(self, conn):\n",
    "        '''\n",
    "        添加一个到上游节点的连接\n",
    "        '''\n",
    "        self.upstream.append(conn)\n",
    "        \n",
    "        \n",
    "    def calc_output(self):\n",
    "        '''\n",
    "        根据式1计算节点的输出\n",
    "        '''\n",
    "        output = reduce(lambda ret, conn: ret + conn.upstream_node.output * conn.weight, self.upstream, 0)\n",
    "        self.output = sigmoid(output)\n",
    "        \n",
    "    def calc_hidden_layer_delta(self):\n",
    "        '''\n",
    "        节点属于隐藏层时，根据式4计算delta\n",
    "        '''\n",
    "        downstream_delta = reduce(\n",
    "                lambda ret, conn : ret + conn.downstream_node.delta * conn.weight, self.downstream, 0.0\n",
    "            )\n",
    "        self.delta = self.output * (1 - self.output) * downstream_delta\n",
    "        \n",
    "    def calc_output_layer_delta(self, label):\n",
    "        '''\n",
    "        节点属于输出层时，根据式3计算delta\n",
    "        '''\n",
    "        self.delta = self.output * (1-self.output)*(label - self.output)\n",
    "    \n",
    "    def __str__(self):\n",
    "        '''\n",
    "        打印节点的信息\n",
    "        '''\n",
    "        node_str = '%u-%u: output: %f delta: %f' % (self.layer_index, self.node_index, self.output, self.delta)\n",
    "        downstream_str = reduce(lambda ret, conn: ret + '\\n\\t' + str(conn), self.downstream, '')\n",
    "        upstream_str = reduce(lambda ret, conn: ret + '\\n\\t' + str(conn), self.upstream, '')\n",
    "        return node_str + '\\n\\tdownstream:' + downstream_str + '\\n\\tupstream:' + upstream_str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constNode对象，实现一个输出恒为1的节点（计算偏置项wb时需要）\n",
    "class ConstNode(object):\n",
    "    def __init__(self, layer_index, node_index):\n",
    "        '''\n",
    "        构造节点对象\n",
    "        layer_index: 节点所属层的编号\n",
    "        node_index: 节点的编号\n",
    "        '''\n",
    "        self.layer_index = layer_index\n",
    "        self.node_index = node_index\n",
    "        self.downstream = []\n",
    "        self.output = 1\n",
    "        \n",
    "    def append_downstream_connection(self, conn):\n",
    "        '''\n",
    "        添加一个到下游节点的连接\n",
    "        '''       \n",
    "        self.downstream.append(conn)\n",
    "    def calc_hidden_layer_delta(self):\n",
    "        '''\n",
    "        节点属于隐藏层时，根据式4计算delta\n",
    "        '''\n",
    "        downstream_delta = reduce(\n",
    "            lambda ret, conn: ret + conn.downstream_node.delta * conn.weight,\n",
    "            self.downstream, 0.0)\n",
    "        self.delta = self.output * (1 - self.output) * downstream_delta\n",
    "    def __str__(self):\n",
    "        '''\n",
    "        打印节点的信息\n",
    "        '''\n",
    "        node_str = '%u-%u: output: 1' % (self.layer_index, self.node_index)\n",
    "        downstream_str = reduce(lambda ret, conn: ret + '\\n\\t' + str(conn), self.downstream, '')\n",
    "        return node_str + '\\n\\tdownstream:' + downstream_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, layer_index, node_count):\n",
    "        '''\n",
    "        初始化一层\n",
    "        layer_index: 层编号\n",
    "        node_count: 层所包含的节点个数\n",
    "        '''\n",
    "        self.layer_index = layer_index\n",
    "        self.nodes = []\n",
    "        for i in range(node_count):\n",
    "            self.nodes.append(Node(layer_index, i))\n",
    "        self.nodes.append(ConstNode(layer_index, node_count))\n",
    "    def set_output(self, data):\n",
    "        '''\n",
    "        设置层的输出。当层是输入层时会用到。\n",
    "        '''\n",
    "        for i in range(len(data)):\n",
    "            self.nodes[i].set_output(data[i])\n",
    "    def calc_output(self):\n",
    "        '''\n",
    "        计算层的输出向量\n",
    "        '''\n",
    "        for node in self.nodes[:-1]:\n",
    "            node.calc_output()\n",
    "    def dump(self):\n",
    "        '''\n",
    "        打印层的信息\n",
    "        '''\n",
    "        for node in self.nodes:\n",
    "            print node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy import *\n",
    "\n",
    "\n",
    "def sigmoid(inX):\n",
    "    return 1.0 / (1 + exp(-inX))\n",
    "\n",
    "class Connection(object):\n",
    "    def __init__(self, upstream_node, downstream_node):\n",
    "        '''\n",
    "        初始化连接，权重初始化为是一个很小的随机数\n",
    "        upstream_node: 连接的上游节点\n",
    "        downstream_node: 连接的下游节点\n",
    "        '''\n",
    "        self.upstream_node = upstream_node\n",
    "        self.downstream_node = downstream_node\n",
    "        self.weight = np.random.uniform(-0.1, 0.1)\n",
    "        self.gradient = 0.0\n",
    "    def calc_gradient(self):\n",
    "        '''\n",
    "        计算梯度\n",
    "        '''\n",
    "        self.gradient = self.downstream_node.delta * self.upstream_node.output\n",
    "    def get_gradient(self):\n",
    "        '''\n",
    "        获取当前的梯度\n",
    "        '''\n",
    "        return self.gradient\n",
    "    def update_weight(self, rate):\n",
    "        '''\n",
    "        根据梯度下降算法更新权重\n",
    "        '''\n",
    "        self.calc_gradient()\n",
    "        self.weight += rate * self.gradient\n",
    "    def __str__(self):\n",
    "        '''\n",
    "        打印连接信息\n",
    "        '''\n",
    "        return '(%u-%u) -> (%u-%u) = %f' % (\n",
    "            self.upstream_node.layer_index, \n",
    "            self.upstream_node.node_index,\n",
    "            self.downstream_node.layer_index, \n",
    "            self.downstream_node.node_index, \n",
    "            self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connections(object):\n",
    "    def __init__(self):\n",
    "        self.connections = []\n",
    "    def add_connection(self, connection):\n",
    "        self.connections.append(connection)\n",
    "    def dump(self):\n",
    "        for conn in self.connections:\n",
    "            print conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network \n",
    "class Network(object):\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        初始化一个全连接神经网络\n",
    "        layers:二维数组，描述神经网络每层节点数\n",
    "        '''\n",
    "        self.connections = Connections()\n",
    "        self.layers = []\n",
    "        layer_count = len(layers)\n",
    "        node_count = 0;\n",
    "        for i in range(layer_count):\n",
    "            self.layers.append(Layer(i, layers[i]))\n",
    "        for layer in range(layer_count - 1):\n",
    "            connections = [Connection(upstream_node, downstream_node) \n",
    "                           for upstream_node in self.layers[layer].nodes\n",
    "                           for downstream_node in self.layers[layer + 1].nodes[:-1]]\n",
    "            for conn in connections:\n",
    "                self.connections.add_connection(conn)\n",
    "                conn.downstream_node.append_upstream_connection(conn)\n",
    "                conn.upstream_node.append_downstream_connection(conn)\n",
    "    \n",
    "    def train(self, labels, data_set, rate, iteration):\n",
    "        '''\n",
    "        训练神经网络\n",
    "        labels: 数组，训练样本标签。每个元素是一个样本的标签。\n",
    "        data_set: 二维数组，训练样本特征。每个元素是一个样本的特征。\n",
    "        '''\n",
    "        for i in range(iteration):\n",
    "            for d in range(len(data_set)):\n",
    "                self.train_one_sample(labels[d], data_set[d], rate)\n",
    "                \n",
    "    def train_one_sample(self, label, sample, rate):\n",
    "        '''\n",
    "        内部函数，用一个样本训练网络\n",
    "        '''\n",
    "        self.predict(sample)\n",
    "        self.calc_delta(label)\n",
    "        self.update_weight(rate)\n",
    "    \n",
    "    def calc_delta(self, label):\n",
    "        '''\n",
    "        内部函数，计算每个节点的delta\n",
    "        '''\n",
    "        output_nodes = self.layers[-1].nodes\n",
    "        for i in range(len(label)):\n",
    "            output_nodes[i].calc_output_layer_delta(label[i])\n",
    "        for layer in self.layers[-2::-1]:\n",
    "            for node in layer.nodes:\n",
    "                node.calc_hidden_layer_delta()\n",
    "                \n",
    "    def update_weight(self, rate):\n",
    "        '''\n",
    "        内部函数，更新每个连接权重\n",
    "        '''\n",
    "        for layer in self.layers[:-1]:\n",
    "            for node in layer.nodes:\n",
    "                for conn in node.downstream:\n",
    "                    conn.update_weight(rate)\n",
    "                    \n",
    "    def calc_gradient(self):\n",
    "        '''\n",
    "        内部函数，计算每个连接的梯度\n",
    "        '''\n",
    "        for layer in self.layers[:-1]:\n",
    "            for node in layer.nodes:\n",
    "                for conn in node.downstream:\n",
    "                    conn.calc_gradient()\n",
    "    def get_gradient(self, label, sample):\n",
    "        '''\n",
    "        获得网络在一个样本下，每个连接上的梯度\n",
    "        label: 样本标签\n",
    "        sample: 样本输入\n",
    "        '''\n",
    "        self.predict(sample)\n",
    "        self.calc_delta(label)\n",
    "        self.calc_gradient()\n",
    "    def predict(self, sample):\n",
    "        '''\n",
    "        根据输入的样本预测输出值\n",
    "        sample: 数组，样本的特征，也就是网络的输入向量\n",
    "        '''\n",
    "        self.layers[0].set_output(sample)\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i].calc_output()\n",
    "        return map(lambda node: node.output, self.layers[-1].nodes[:-1])\n",
    "    def dump(self):\n",
    "        '''\n",
    "        打印网络信息\n",
    "        '''\n",
    "        for layer in self.layers:\n",
    "            layer.dump()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(network, sample_feature, sample_label):\n",
    "    '''\n",
    "    梯度检查\n",
    "    network: 神经网络对象\n",
    "    sample_feature: 样本的特征\n",
    "    sample_label: 样本的标签\n",
    "    '''\n",
    "    # 计算网络误差\n",
    "    network_error = lambda vec1, vec2: \\\n",
    "            0.5 * reduce(lambda a, b: a + b, \n",
    "                      map(lambda v: (v[0] - v[1]) * (v[0] - v[1]),\n",
    "                          zip(vec1, vec2)))\n",
    "    # 获取网络在当前样本下每个连接的梯度\n",
    "    network.get_gradient(sample_feature, sample_label)\n",
    "    # 对每个权重做梯度检查    \n",
    "    for conn in network.connections.connections: \n",
    "        # 获取指定连接的梯度\n",
    "        actual_gradient = conn.get_gradient()\n",
    "        # 增加一个很小的值，计算网络的误差\n",
    "        epsilon = 0.0001\n",
    "        conn.weight += epsilon\n",
    "        error1 = network_error(network.predict(sample_feature), sample_label)\n",
    "        # 减去一个很小的值，计算网络的误差\n",
    "        conn.weight -= 2 * epsilon # 刚才加过了一次，因此这里需要减去2倍\n",
    "        error2 = network_error(network.predict(sample_feature), sample_label)\n",
    "        # 根据式6计算期望的梯度值\n",
    "        expected_gradient = (error2 - error1) / (2 * epsilon)\n",
    "        # 打印\n",
    "        print 'expected gradient: \\t%f\\nactual gradient: \\t%f' % (\n",
    "            expected_gradient, actual_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-\n",
    "import struct\n",
    "from bp import *\n",
    "from datetime import datetime\n",
    "# 数据加载器基类\n",
    "class Loader(object):\n",
    "    def __init__(self, path, count):\n",
    "        '''\n",
    "        初始化加载器\n",
    "        path: 数据文件路径\n",
    "        count: 文件中的样本个数\n",
    "        '''\n",
    "        self.path = path\n",
    "        self.count = count\n",
    "    def get_file_content(self):\n",
    "        '''\n",
    "        读取文件内容\n",
    "        '''\n",
    "        f = open(self.path, 'rb')\n",
    "        content = f.read()\n",
    "        f.close()\n",
    "        return content\n",
    "    def to_int(self, byte):\n",
    "        '''\n",
    "        将unsigned byte字符转换为整数\n",
    "        '''\n",
    "        return struct.unpack('B', byte)[0]\n",
    "\n",
    "\n",
    "# 图像数据加载器\n",
    "class ImageLoader(Loader):\n",
    "    def get_picture(self, content, index):\n",
    "        '''\n",
    "        内部函数，从文件中获取图像\n",
    "        '''\n",
    "        start = index * 28 * 28 + 16\n",
    "        picture = []\n",
    "        for i in range(28):\n",
    "            picture.append([])\n",
    "            for j in range(28):\n",
    "                picture[i].append(\n",
    "                    self.to_int(content[start + i * 28 + j]))\n",
    "        return picture\n",
    "    def get_one_sample(self, picture):\n",
    "        '''\n",
    "        内部函数，将图像转化为样本的输入向量\n",
    "        '''\n",
    "        sample = []\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                sample.append(picture[i][j])\n",
    "        return sample\n",
    "    def load(self):\n",
    "        '''\n",
    "        加载数据文件，获得全部样本的输入向量\n",
    "        '''\n",
    "        content = self.get_file_content()\n",
    "        data_set = []\n",
    "        for index in range(self.count):\n",
    "            data_set.append(\n",
    "                self.get_one_sample(\n",
    "                    self.get_picture(content, index)))\n",
    "        return data_set\n",
    "    \n",
    "# 标签数据加载器\n",
    "class LabelLoader(Loader):\n",
    "    def load(self):\n",
    "        '''\n",
    "        加载数据文件，获得全部样本的标签向量\n",
    "        '''\n",
    "        content = self.get_file_content()\n",
    "        labels = []\n",
    "        for index in range(self.count):\n",
    "            labels.append(self.norm(content[index + 8]))\n",
    "        return labels\n",
    "    def norm(self, label):\n",
    "        '''\n",
    "        内部函数，将一个值转换为10维标签向量\n",
    "        '''\n",
    "        label_vec = []\n",
    "        label_value = self.to_int(label)\n",
    "        for i in range(10):\n",
    "            if i == label_value:\n",
    "                label_vec.append(0.9)\n",
    "            else:\n",
    "                label_vec.append(0.1)\n",
    "        return label_vec\n",
    "    \n",
    "def get_training_data_set():\n",
    "    '''\n",
    "    获得训练数据集\n",
    "    '''\n",
    "    image_loader = ImageLoader('train-images.idx3-ubyte', 60000)\n",
    "    label_loader = LabelLoader('train-labels.idx1-ubyte', 60000)\n",
    "    return image_loader.load(), label_loader.load()\n",
    "def get_test_data_set():\n",
    "    '''\n",
    "    获得测试数据集\n",
    "    '''\n",
    "    image_loader = ImageLoader('t10k-images.idx3-ubyte', 10000)\n",
    "    label_loader = LabelLoader('t10k-labels.idx1-ubyte', 10000)\n",
    "    return image_loader.load(), label_loader.load()    \n",
    "\n",
    "def get_result(vec):\n",
    "    max_value_index = 0\n",
    "    max_value = 0\n",
    "    for i in range(len(vec)):\n",
    "        if vec[i] > max_value:\n",
    "            max_value = vec[i]\n",
    "            max_value_index = i\n",
    "    return max_value_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(network, test_data_set, test_labels):\n",
    "    error = 0\n",
    "    total = len(test_data_set)\n",
    "    for i in range(total):\n",
    "        label = get_result(test_labels[i])\n",
    "        predict = get_result(network.predict(test_data_set[i]))\n",
    "        if label != predict:\n",
    "            error += 1\n",
    "    return float(error) / float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4678aae35e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mlast_error_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-4678aae35e5c>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'%s epoch %d finished'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-34306195ced6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, labels, data_set, rate, iteration)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_one_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-34306195ced6>\u001b[0m in \u001b[0;36mtrain_one_sample\u001b[0;34m(self, label, sample, rate)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-34306195ced6>\u001b[0m in \u001b[0;36mupdate_weight\u001b[0;34m(self, rate)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                     \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_and_evaluate():\n",
    "    last_error_ratio = 1.0\n",
    "    epoch = 0\n",
    "    train_data_set, train_labels = get_training_data_set()\n",
    "    test_data_set, test_labels = get_test_data_set()\n",
    "    network = Network([784, 300, 10])\n",
    "    while True:\n",
    "        epoch += 1\n",
    "        network.train(train_labels, train_data_set, 0.3, 1)\n",
    "        print '%s epoch %d finished' % (now(), epoch)\n",
    "        if epoch % 10 == 0:\n",
    "            error_ratio = evaluate(network, test_data_set, test_labels)\n",
    "            print '%s after epoch %d, error ratio is %f' % (now(), epoch, error_ratio)\n",
    "            if error_ratio > last_error_ratio:\n",
    "                break\n",
    "            else:\n",
    "                last_error_ratio = error_ratio\n",
    "if __name__ == '__main__':\n",
    "    train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
